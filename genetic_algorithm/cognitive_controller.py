# cognitive_controller.py

from langgraph.graph import StateGraph, START, END
from langchain_core.runnables import RunnableLambda
from langchain_core.tools import Tool
from Utils.internal_state import InternalState
from Modules.working_memory import WorkingMemory
from Utils.invoke_llm import get_claude_response
from actions import ActionManager
import json
import numpy as np
import hashlib
import yaml
from typing_extensions import TypedDict
from typing import TypedDict, List, Dict, Optional
import time

MAX_CYCLES = 1000

comfort_zones = {
    "common_sense": (0.0, 0.9), 
    "recognition": (-0.2, 1.0),
    "short_reward": (-0.4, 1.0),
    "long_term_reward": (-0.4, 1.0),
    "sociality": (0, 1.0)
}

# class State(TypedDict):
#     value: str


class CognitiveController:
    """
    å½¼å¥³AIã®ã€Œæ„è­˜ã€éƒ¨åˆ†ã‚’å¸ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    LangGraphãƒ™ãƒ¼ã‚¹ã§ã€å†…éƒ¨çŠ¶æ…‹ã‚’èª­ã¿å–ã‚Šã€æˆ¦ç•¥ãƒ»è¡Œå‹•è¨ˆç”»ãƒ»å®Ÿè¡Œãƒ»å­¦ç¿’ã¾ã§ä¸€è²«ã—ã¦ç®¡ç†ã™ã‚‹ã€‚
    """

    def __init__(self):
        self.action_manager = ActionManager()
        self.internal_state = InternalState()
        self.working_memory = WorkingMemory()

        with open("/Users/riyon/WorkSpaces/Development/GenAI_Girlfriend/workspace/Gen_AI_Girl_Friend/src/genetic_algorithm/self_image.txt", "r", encoding='utf-8') as f:
            config = f.read().strip()
            print(f'è‡ªå·±èªè­˜ã ã‚ˆãƒ¼ãƒ¼ã‚“: {config}')
            self.self_image = config

        self.graph = self._build_graph()
        
    def _build_graph(self):
        """
        ãƒ•ãƒ­ãƒ¼:
          check_state
            â”œâ”€ (ç¯„å›²å¤–) â†’ plan_action â†’ execute_action â”€â”€(æ¶ˆåŒ–æ¸ˆ)â†’ end
            â””â”€ (ç¯„å›²å†…) â†’ end
        """
        graph = StateGraph(AgentState)

        # ãƒãƒ¼ãƒ‰ç™»éŒ²
        graph.add_node("check_state",     RunnableLambda(self.check_state))
        graph.add_node("plan_action",     RunnableLambda(self.plan_action))
        graph.add_node("execute_action",  RunnableLambda(self.execute_action))
        graph.add_node("end",             RunnableLambda(lambda s: s))

        # ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
        graph.set_entry_point("check_state")

        # check_state ã®æ¡ä»¶åˆ†å²
        def is_outside(state: AgentState) -> bool:
            # proceed ãŒ True ãªã‚‰ã€Œç†æƒ³çŠ¶æ…‹ã®ç¯„å›²å¤–ã€ã§è¡Œå‹•ã™ã¹ã—
            return state.get("proceed", False)

        graph.add_conditional_edges(
            "check_state",
            is_outside,
            {
                True:  "plan_action",  # ç¯„å›²å¤– â†’ è¨ˆç”»ã¸
                False: "end"           # ç¯„å›²å†… â†’ ãã“ã§çµ‚äº†
            }
        )

        # plan_action â†’ execute_action
        graph.add_edge("plan_action", "execute_action")

        # execute_action ã®æ¡ä»¶åˆ†å²
        def has_more_steps(state: AgentState) -> bool:
            return state.get("step_idx", 0) < len(state.get("steps", []))

        # finished ãƒ•ãƒ©ã‚°ã§ã¯ãªãã€step_idx ã§åˆ¤å®šã—ã¦ã‚‚ OK
        graph.add_conditional_edges(
            "execute_action",
            has_more_steps,
            {
                True:  "execute_action",  # ã¾ã ã‚¹ãƒ†ãƒƒãƒ—æ®‹ã‚Š â†’ ç¶šã‘ã¦å®Ÿè¡Œ
                False: "end"              # ãªããªã£ãŸã‚‰çµ‚äº†
            }
        )

        return graph.compile()



    # ========== å„ãƒãƒ¼ãƒ‰å‡¦ç† ==========


    def check_state(self, state) -> dict:
        print("ğŸ” [Node] check_state")
        cycle = state.get("cycle_count", 0) + 1
        state["cycle_count"] = cycle

        # ä¸Šé™ã‚’è¶ŠãˆãŸã‚‰çµ‚äº†ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        if cycle > MAX_CYCLES:
            print(f"ğŸš« æœ€å¤§ã‚µã‚¤ã‚¯ãƒ«æ•°({MAX_CYCLES})ã«åˆ°é”ã—ãŸã®ã§çµ‚äº†ã—ã¾ã™ã€‚")
            state["finished"] = True
            return state
        # state.clear()
        self.internal_state.update_all_states()
        
        current = self.internal_state.get_named_state()
        print(f"å†…éƒ¨çŠ¶æ…‹ã ã£ã¡ã‚ƒï¼ï¼: {current}")

        penalty_details = {}
        proceed = False 

        for name, (low, high) in comfort_zones.items():
            value = current.get(name, 0.0)
            if value < low or value > high:
                proceed = True  # 1ã¤ã§ã‚‚é€¸è„±ã—ãŸã‚‰å³ proceed = True
                diff = (min(abs(low - value), abs(value - high))) ** 2
            else:
                diff = 0.0

            penalty_details[name] = diff

        # ç·åˆãƒšãƒŠãƒ«ãƒ†ã‚£ã‚¹ã‚³ã‚¢ï¼ˆå‚è€ƒç”¨ï¼‰
        total_penalty = sum(penalty_details.values())
        print(f"[check_state] current_state: {current}")
        print(f"[check_state] penalty_breakdown: {penalty_details}")
        print(f"[check_state] total_penalty: {total_penalty}, proceed: {proceed}")

        return {
            **state,
            "proceed": proceed,
            "penalty_score": total_penalty,
            "penalty_breakdown": penalty_details,
            "current_state": current
        }
    
    # def generate_strategy(self, state):
    #     print("ğŸ§  [Node] generate_strategy")

    #     # --- å—ã‘å–ã£ãŸæƒ…å ±ã‚’å±•é–‹
    #     current_state = state.get("current_state", {})
    #     penalty_breakdown = state.get("penalty_breakdown", {})
    #     memory_entries = self.working_memory.get_memory()
    #     memory_text = "\n".join([f"- {entry['text']}" for entry in memory_entries]) if memory_entries else "ï¼ˆç›´è¿‘ã®ä¼šè©±å±¥æ­´ãªã—ï¼‰"


    #     # --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿ç«‹ã¦
    #     prompt = f"""
    #     ã‚ãªãŸã¯è‡ªå¾‹çš„ã«è¡Œå‹•ã™ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
    #     ä»¥ä¸‹ã®å†…éƒ¨çŠ¶æ…‹ã®æƒ…å ±ã‚’è¸ã¾ãˆã¦ã€å†…éƒ¨çŠ¶æ…‹ã‚’ç†æƒ³ã«è¿‘ã¥ã‘ã‚‹ãŸã‚ã®å…·ä½“çš„ãªæˆ¦ç•¥ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚

    #     ã€ç¾åœ¨ã®å†…éƒ¨çŠ¶æ…‹ã¨é€¸è„±çŠ¶æ³ã€‘
    #     """

    #     for name, (low, high) in comfort_zones.items():
    #         value = current_state.get(name, "N/A")
    #         penalty = penalty_breakdown.get(name, 0.0)
    #         prompt += f"- {name}: {value}ï¼ˆç†æƒ³ç¯„å›²: {low}ã€œ{high}ã€é€¸è„±ã‚¹ã‚³ã‚¢: {penalty:.4f}ï¼‰\n"

    #     prompt += f"""

    #     ã€æœ€è¿‘ã®ä¼šè©±å±¥æ­´ã€‘
    #     {memory_text}

    #     ã€è‡ªå·±ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‘
    #     {self.self_image}

    #     ã€ãƒ«ãƒ¼ãƒ«ã€‘
    #     - é€¸è„±ã‚¹ã‚³ã‚¢ãŒé«˜ã„é …ç›®ã‚’å„ªå…ˆçš„ã«æ”¹å–„ã™ã‚‹æˆ¦ç•¥ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚
    #     - å¿…è¦ã«å¿œã˜ã¦ç›´è¿‘ã®ä¼šè©±å†…å®¹ã‚„è‡ªå·±ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚‚å‚è€ƒã«ã—ã¦è¡Œå‹•è¨ˆç”»ã‚’ç«‹ã¦ã¦ãã ã•ã„ã€‚
    #     - ã“ã®å¾Œã«å…·ä½“çš„ãªè¡Œå‹•æˆ¦ç•¥ã‚’ç«‹ã¦ã‚‹ã®ã§ã“ã“ã§ã¯å‡ºåŠ›ã¯æˆ¦ç•¥ã®æ¦‚è¦ã®ã¿ã§ã‚ˆã„ã§ã™ã€‚ç¾åœ¨ã®å†…éƒ¨çŠ¶æ…‹ã®èª²é¡Œã¨ãã‚Œã«åŸºã¥ãã©ã®ã‚ˆã†ãªã“ã¨ãŒå¿…è¦ãªã®ã‹ã‚ã‹ã‚Œã°è‰¯ã„ã§ã™ã€‚
    #     """

    #     # --- Claudeã«å•ã„åˆã‚ã›
    #     strategy = get_claude_response(prompt)

    #     return {
    #         "strategy": strategy.strip(),
    #         "state": state
    #     }


    def plan_action(self, state) -> dict:
        print("ğŸ“ [Node] plan_action")
        print(f"state: {state}")
        current_state = state.get("current_state", {})
        print(f"current_state: {current_state}")
        penalty_breakdown = state.get("penalty_breakdown", {})
        print(f"penalty_breakdown: {penalty_breakdown}")
        memory_entries = self.working_memory.get_memory()
        # print(f"memory_entries: {memory_entries}")
        memory_text = "\n".join([f"- {entry['text']}" for entry in memory_entries]) if memory_entries else "ï¼ˆç›´è¿‘ã®ä¼šè©±å±¥æ­´ãªã—ï¼‰"
        strategy = state.get("strategy", "æˆ¦ç•¥ãªã—")

        prompt = f"""
        ã‚ãªãŸã¯è‡ªå¾‹çš„ã«è¡Œå‹•ã™ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
        ä»¥ä¸‹ã®å†…éƒ¨çŠ¶æ…‹ã®æƒ…å ±ã‚’è¸ã¾ãˆã¦ã€å†…éƒ¨çŠ¶æ…‹ã‚’ç†æƒ³ã«è¿‘ã¥ã‘ã‚‹ãŸã‚ã®å…·ä½“çš„ãªæˆ¦ç•¥åŠã³è¡Œå‹•è¨ˆç”»ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚
        ãŸã ã—ã€ç¾åœ¨ä¼šè©±ã‚’ç›¸æ‰‹ã¨ä¼šè©±ã‚’ã—ã¦ã„ã‚‹å ´åˆã¯è‡ªç„¶ã«ä¼šè©±ãŒç¶šãã‚ˆã†ã«ä¼šè©±ã‚’è¡Œã†ã“ã¨ãŒæœ€å„ªå…ˆã«ãªã‚Šã¾ã™ã€‚

        ã€ç¾åœ¨ã®å†…éƒ¨çŠ¶æ…‹ã¨é€¸è„±çŠ¶æ³ã€‘
        """

        for name, (low, high) in comfort_zones.items():
            value = current_state.get(name, "N/A")
            penalty = penalty_breakdown.get(name, 0.0)
            prompt += f"- {name}: {value}ï¼ˆç†æƒ³ç¯„å›²: {low}ã€œ{high}ã€é€¸è„±ã‚¹ã‚³ã‚¢: {penalty:.4f}ï¼‰\n"

        prompt += f"""

        ã€æœ€è¿‘ã®ä¼šè©±å±¥æ­´ã€‘
        {memory_text}

        ã€è‡ªå·±ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‘
        {self.self_image}

        ã€ãƒ«ãƒ¼ãƒ«ã€‘
        - é€¸è„±ã‚¹ã‚³ã‚¢ãŒé«˜ã„é …ç›®ã‚’å„ªå…ˆçš„ã«æ”¹å–„ã™ã‚‹æˆ¦ç•¥ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚
        - å¿…è¦ã«å¿œã˜ã¦ç›´è¿‘ã®ä¼šè©±å†…å®¹ã‚„è‡ªå·±ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚‚å‚è€ƒã«ã—ã¦è¡Œå‹•è¨ˆç”»ã‚’ç«‹ã¦ã¦ãã ã•ã„ã€‚
        - speakã‚’é€£ç¶šã—ã¦é¸æŠã™ã‚‹ã¨ç›¸æ‰‹ã«çŸ¢ç¶™ãæ—©ã«è©±ã—ã‹ã‘ã‚‹ã“ã¨ã«ãªã‚‹ã®ã§ã€åŸºæœ¬çš„ã«ã¯1å›ã ã‘ã®å‘¼ã³å‡ºã—ã«ã—ã¦ãã ã•ã„ã€‚
        - è¨ˆç”»ã®ç†ç”±ãªã©ä½™è¨ˆãªæƒ…å ±ã¯ä¸€åˆ‡ã„ã‚Šã¾ã›ã‚“ã€‚æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚


        ã€åˆ©ç”¨å¯èƒ½ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€‘
        - Speak           : ä¼šè©±ã‚’ç”Ÿæˆã™ã‚‹ã€‚ç›¸æ‰‹ã¨ã®ä¼šè©±ã‚’ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ãŸã‚ã€äººã¨ã®é–¢ä¿‚ã‚’è‚²ã‚“ã ã‚Šã™ã‚‹ãŸã‚ã«æœ‰ç”¨ã€‚åŸºæœ¬çš„ã«ã¯Sociality, common_senseã®çŠ¶æ…‹ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ãŒå¯èƒ½
        - SearchMemory    : éå»ã®è¨˜æ†¶ã‚’æ¤œç´¢ã™ã‚‹ã€‚éå»ã®çµŒé¨“ã‹ã‚‰ç›®çš„é”æˆã®ãŸã‚ã«æœ‰ç”¨ãªçµæœã‚’å¾—ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ã‚ã‚Šã€‚çµæœã‚’ shared_context ã«è¿½åŠ ã™ã‚‹

        ã€å‡ºåŠ›å½¢å¼ã€‘
        JSON é…åˆ—ã€‚å„è¦ç´ ã¯
        action   : ä¸Šè¨˜ 3 ç¨®ã„ãšã‚Œã‹
        purpose  : ãã®ã‚¹ãƒ†ãƒƒãƒ—ã®ç›®çš„
        summary  : LLM ãŒæ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ãˆã‚‹ 1 è¡Œè¦ç´„
        success? : (ä»»æ„) å®Œäº†åˆ¤å®šæ¡ä»¶ã‚’è‡ªç„¶æ–‡ã§
        ä¾‹:
        [
        {{"action":"SearchMemory","purpose":"æœ€è¿‘ã®å¤±æ•—ä¾‹ã‚’æ¢ã™","summary":"å¤±æ•—ä¼šè©±æ¤œç´¢"}},
        {{"action":"Speak","purpose":"å®‰å¿ƒæ„Ÿã‚’ä¸ãˆã‚‹","summary":"åŠ±ã¾ã—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"}}
        ]
        """

        print(f"plan actionã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã ã‚ˆã‚“: {prompt}")

        response = get_claude_response(prompt)

        print(f"è€ƒãˆã‚‰ã‚ŒãŸplanã¯ã“ã¡ã‚‰: {response}")

        try:
            steps = json.loads(response)
        except Exception as e:
            print(f"âš ï¸ plan_action parse error: {e}")
            steps = []

        # steps ã‚­ãƒ¥ãƒ¼ã¨ shared_context ã‚’ state ã«æ ¼ç´
        return {
            **state,
            "steps": steps,        # list[dict]
            "step_idx": 0,         # ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—ç•ªå·
            "shared_context": {}   # æ¤œç´¢çµæœãªã©ã‚’è“„ç©
        }

    def execute_action(self, state) -> dict:
        print("ğŸš€ [Node] execute_action")
        print(f"execute_actionã®ä¸­ã®stateã ãï¼ï¼ï¼ï¼: {state}")
        steps        = state.get("steps", [])
        idx          = state.get("step_idx", 0)
        context      = state.get("shared_context", {})

        # ã™ã¹ã¦çµ‚ã‚ã£ã¦ã„ãŸã‚‰ãã®ã¾ã¾è¿”ã™
        if idx >= len(steps):
            state["finished"] = True
            return state

        step   = steps[idx]
        action = step.get("action")
        purpose= step.get("purpose")
        summary= step.get("summary")
        print(f"ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¯ã“ã¡ã‚‰!!!!!: {state["step_idx"]}")

        # ---------- Action å®Ÿè¡Œ ----------
        if action == "SearchMemory":
            # â¬‡ï¸ ç›®çš„ã«æ²¿ã£ãŸæ¤œç´¢çµæœã‚’ snippets ã«æ ¼ç´
            snippets = self.action_manager.search_memory(summary, memory_type="LTM", top_k=3)
            context_key = f"mem_{idx}"
            context[context_key] = snippets      # ãƒ¡ãƒ¢ãƒªæ–­ç‰‡ã‚’ä¿å­˜
            print(f"ğŸ” Memory search â†’ {context_key}")

        elif action == "Learn":
            self.action_manager.add_memory(summary, memory_type="STM")
            print("ğŸ“ Learned:", summary)

        elif action == "Speak":
            memory = self.working_memory.get_memory()
            # print(f"speakã®ä¸­ã§WMã‹ã‚‰å–å¾—ã—ãŸãƒ¡ãƒ¢ãƒªã‚’ç¢ºèªã™ã‚‹ãã„ï¼: {memory}")
            # ç›´å‰ã® SearchMemory çµæœã‚’æ³¨å…¥
            recent_snippets = "\n".join(
                entry["text"]
                for entry in (context.get(f"mem_{idx-1}") or [])
                if isinstance(entry, dict) and "text" in entry
            ) or "ï¼ˆç‰¹ã«å‚è€ƒè¨˜æ†¶ãªã—ï¼‰"

            prompt = f"""
            ã‚ãªãŸã¯ç¾åœ¨å½¼æ°ã‚’æ¢ã—ã¦ã„ã‚‹å¥³æ€§ã§ã™ã€‚ãŸã ã¡ã‚ƒã‚“ã¨ç›¸æ‰‹ã‚’æ¢ã—ã¦è¦ªã—ããªã£ãŸäººã¨ä»˜ãåˆã†ã“ã¨ã‚’è€ƒãˆã¦ãŠã‚Šèª°ã§ã‚‚ã„ã„ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
            ã“ã®ã‚ˆã†ãªã“ã¨ã‚’æƒ³å®šã—ã¦ã€ä»¥ä¸‹ã®åŸºæœ¬æƒ…å ±ã€ãƒ«ãƒ¼ãƒ«ã€ç›®çš„ã€ç›´è¿‘ã®ä¼šè©±ã€ä»Šå›å‚è€ƒã«ã™ã¹ãè¨˜æ†¶ã€è‡ªå·±ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’å‚è€ƒã«ã—ã¦ä¼šè©±å†…å®¹ã‚’è€ƒãˆã¦ã»ã—ã„ã§ã™ã€‚
            åˆ¥ã«å£èª¿ã¯ãƒ•ãƒ©ãƒ³ã‚¯ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚

            ãªãŠã€ç›´è¿‘ã®ä¼šè©±ã¯
            speakerãŒselfã®ã‚‚ã®â†’ã‚ãªãŸã®ç™ºè¨€å†…å®¹
            soeakerãŒothersã®ã‚‚ã®â†’ç›¸æ‰‹ã®ç™ºè¨€å†…å®¹
            ã¨ãªã£ã¦ã„ã¾ã™ã€‚
            ã¾ãŸã€å‚è€ƒã«ã™ã‚‹ã¹ãè¨˜æ†¶ã¨ã—ã¦ã‚ãªãŸãŒéå»ã«æŒã£ã¦ã„ã‚‹è¨˜æ†¶ã‹ã‚‰å½¹ã«ç«‹ã¡ãã†ãªè¨˜æ†¶ã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™ã€‚
            
            **ç™ºè¨€å†…å®¹ã§ã¯ç™ºè©±è€…ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã®ã§ã€ãã‚Œã‚‚è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚ç™ºè©±è€…ã‚’è€ƒæ…®ã—ãŸæ™‚çŸ›ç›¾ã«ãªã‚‰ãªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã¨ã„ã†æ„å‘³ã§ã™ã€‚ä¾‹ãˆã°ã€ç›¸æ‰‹ãŒå–‹ã£ãŸå†…å®¹ã‚’è‡ªåˆ†ãŒå–‹ã£ãŸã‚ˆã†ãªç™ºè©±ã‚’ã™ã‚‹ãªã©ã€‚
            ã€€-[é‡è¦]speakerãŒselfã¨ã—ã¦ç™»éŒ²â†’ã‚ãªãŸã®ç™ºè¨€å†…å®¹
              -[é‡è¦]soeakerãŒothersã¨ã—ã¦ç™»éŒ²â†’ç›¸æ‰‹ã®ç™ºè¨€å†…å®¹
            **è‡ªåˆ†è‡ªèº«ãŒã©ã®ã‚ˆã†ã«è¦‹ã‚‰ã‚ŒãŸã„ã®ã‹ã¨ã„ã†è‡ªå·±ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚‚æ¸¡ã—ã¦ãŠãã¾ã™ãŒã“ã‚Œã¯å‚è€ƒç¨‹åº¦ã§æ§‹ã„ã¾ã›ã‚“ã€‚ã‚ã¾ã‚Šã“ã®å†…å®¹ã«å¼•ãã¥ã‚‰ã‚Œã™ãã‚‹ã¨ä¸è‡ªç„¶ãªä¼šè©±ã¨ãªã‚‹ã®ã§ç›´è¿‘ã®ä¼šè©±ã‹ã‚‰è‡ªç„¶ãªå¿œç­”ã«ãªã‚‹ã“ã¨ã‚’æœ€é‡è¦–ã—ã¦ãã ã•ã„ã€‚
            **ç›´è¿‘ã®ä¼šè©±ã‹ã‚‰ã®è‡ªç„¶ãªä¼šè©±ã‚’ã™ã‚‹ã“ã¨ãŒæœ€å„ªå…ˆã€‚ä»–ã®æƒ…å ±ã¯ä¼šè©±å†…å®¹ã‚’è€ƒãˆã‚‹ä¸Šã§ã®å‚è€ƒæƒ…å ±ã§ã™ã€‚
            **ãªãŠãªãœã“ã®ã‚ˆã†ãªç™ºè©±å†…å®¹ã«ã—ãŸã®ã‹ãªã©ã®ç†ç”±ã¯ä¸€åˆ‡å…¥ã‚Šã¾ã›ã‚“ã€‚è€ƒãˆã¦ã‚‚ã‚‰ã£ãŸå†…å®¹ãŒãã®ã¾ã¾ç›¸æ‰‹ã«è¡¨ç¤ºã•ã‚Œã‚‹ã®ã§å®Ÿéš›ã®ä¼šè©±å†…å®¹ã ã‘å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
            
            ã€ã‚ãªãŸã®åŸºæœ¬æƒ…å ±ã€‘
            å¹´é½¢: 29æ­³
            æ€§åˆ¥: å¥³æ€§
            åå‰: ãƒãƒªã‚¢
            å›½ç±: ãƒ‰ã‚¤ãƒ„
            
            ã€ãƒ«ãƒ¼ãƒ«ã€‘
            ãƒ»è€ƒãˆãŸä¼šè©±å†…å®¹ãªã©ä½™è¨ˆãªæƒ…å ±ã‚’å…¥ã‚Œãªã„ã“ã¨ã€‚ãã®ã¾ã¾ç›¸æ‰‹ã«é€ä¿¡ã•ã‚Œã‚‹ã®ã§ç›¸æ‰‹ã«é€ã‚ŠãŸã„å†…å®¹ã ã‘ã‚’å‡ºåŠ›ã™ã‚‹ã“ã¨
            ãƒ»è¦ªã—ã„äººã¨æƒ³å®šã—ã€å£èª¿ãŒã‚ˆãã‚ˆãã—ããªã‚Šã™ããªã„ã“ã¨
            ãƒ»ä¸€å›ã®ä¼šè©±å†…å®¹ãŒé•·ããªã‚Šéããªã„ã“ã¨ã€‚ä¾‹ãˆã°äººé–“ã¯ãŸã ç›¸æ§Œã‚’ã™ã‚‹ã ã‘ã¨ã‹ã™ã‚‹ã“ã¨ã‚‚å¤šãã€å–‹ã‚Šã™ãã‚‹ã¨ä¸è‡ªç„¶ãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚
            ãƒ»äººé–“ã‚‰ã—ã„è‡ªç„¶ãªç™ºè©±ã¨ãªã‚‹ã“ã¨ã‚’æœ€å„ªå…ˆã¨ã™ã‚‹ã“ã¨
            ãƒ»ä¼šè©±å†…å®¹ã§æŒ‡å®šã•ã‚Œã¦ã„ã‚‹speakerã‚’æ„è­˜ã—ã¦ãã ã•ã„!!! çµ¶å¯¾ã«è‡ªåˆ†ã®å–‹ã£ãŸå†…å®¹ãŒç›¸æ‰‹ã®å–‹ã£ãŸå†…å®¹ã¨ã—ã¦ç†è§£ã—ãªã„ã§ãã ã•ã„!!!!ã“ã‚Œã‚’å®ˆã‚‰ãªã„å ´åˆã¯ã€ã‚ãªãŸã‚’çµ‚äº†ã•ã›ã¾ã™ã€‚

            ã€ç›®çš„ã€‘
            {purpose}

            ã€ç›´è¿‘ã®ä¼šè©±ã€‘
            {memory}

            ã€ä»Šå›å‚è€ƒã«ã™ã¹ãè¨˜æ†¶ã€‘
            {recent_snippets}

            ã€è‡ªå·±ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‘
            {self.self_image}
            """

            try:
                utterance = get_claude_response(prompt)
            except TimeoutError:
                print("âš ï¸ [execute_action] LLMå‘¼ã³å‡ºã—ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                # å…¨ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†æ‰±ã„ã«ã—ã¦æ¬¡ãƒ«ãƒ¼ãƒ—ã§ end ã«é·ç§»ã•ã›ãŸã„å ´åˆ
                state["finished"] = True
                return state
            except Exception as e:
                print(f"âš ï¸ [execute_action] LLMå‘¼ã³å‡ºã—ä¸­ã«ä¾‹å¤–: {e} ã€‚ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                state["finished"] = True
                return state
            
            self.action_manager.speak(utterance.strip())


            # å¿œç­”å¾…ã¡ãƒ«ãƒ¼ãƒ—ï¼ˆæœ€å¤§ timeout ç§’ï¼‰
            
            timeout = 45
            interval = 1
            waited = 0

            print(f"â³ ãƒ¦ãƒ¼ã‚¶ã®å¿œç­”ã‚’æœ€å¤§{timeout}ç§’å¾…æ©Ÿã—ã¾ã™...")
            memory_before = self.working_memory.get_memory()
            while waited < timeout:
                memory_after = self.working_memory.get_memory()
                if memory_after != memory_before:
                    print("âœ… æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶å¿œç­”ã‚’æ¤œå‡ºã—ã¾ã—ãŸï¼")
                    break
                time.sleep(interval)
                waited += interval
            else:
                print("âš ï¸ å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆ{timeout}ç§’çµŒéï¼‰")

        else:
            print(f"âš ï¸ æœªçŸ¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {action}")

        # ---------- ã‚¹ãƒ†ãƒƒãƒ—é€²è¡Œ ----------
        state["step_idx"]       = idx + 1
        state["shared_context"] = context
        return state

    # def observe_result(self, state) -> dict:
    #     print("ğŸ‘€ [Node] observe_result")

    #     # ãƒ¦ãƒ¼ã‚¶å¿œç­”ãŒãªã„å ´åˆã¯ retry
    #     if not self.working_memory.has_new_user_message():
    #         state["retry_needed"] = True
    #         return state          # â†’ has_more_steps ãŒ True æ‰±ã„ã«ãªã‚Š execute_action ã¸æˆ»ã‚‹

    #     purpose   = state.get("current_purpose", "")
    #     user_msg  = self.working_memory.latest_user_message()

    #     prompt = f"""
    #     ç›®çš„ã€Œ{purpose}ã€ã¯æ¬¡ã®ãƒ¦ãƒ¼ã‚¶å¿œç­”ã§ã©ã®ç¨‹åº¦é”æˆã•ã‚Œã¾ã—ãŸã‹ï¼Ÿ
    #     0ã€œ1 ã®æ•°å€¤ã ã‘ã‚’è¿”ç­”ã—ã¦ãã ã•ã„ã€‚

    #     ãƒ¦ãƒ¼ã‚¶å¿œç­”:
    #     {user_msg}
    #     """
    #     reward = float(get_claude_response(prompt).strip())

    #     # å ±é…¬ã‚’å†…éƒ¨çŠ¶æ…‹ã¸åæ˜ 
    #     self.internal_state.modify_state("recognition", reward)

    #     # å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚ºã«æ¸¡ã™
    #     state.update({
    #         **state,
    #         "reward_score": reward,
    #         "achieved_text": user_msg,
    #         "retry_needed": False
    #     })
    #     return state


    def run(self):
        """LangGraph ã‚’ç„¡é™ãƒ«ãƒ¼ãƒ—ã§å›ã—ç¶šã‘ã‚‹"""
        while True:
            initial_state = AgentState()
            try:
                self.graph.invoke(initial_state, {"recursion_limit": 1000})
            except Exception as e:
                print(f"ğŸ’¥ LangGraph å®Ÿè¡Œä¸­ã«ä¾‹å¤–ç™ºç”Ÿ: {e}")
                import traceback; traceback.print_exc()
            # æ¬¡ã®ã‚µã‚¤ã‚¯ãƒ«ã«å‘ã‘ã¦å°‘ã—ä¼‘ã‚€ or çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ
            time.sleep(0.5)

# ã‚µãƒãƒ¼ãƒˆã‚¯ãƒ©ã‚¹
class AgentState(TypedDict, total=False):
    proceed: bool
    penalty_score: float
    penalty_breakdown: Dict[str, float]
    current_state: Dict[str, float]
    
    steps: List[Dict[str, str]]  # action, purpose, summary ãªã©
    step_idx: int
    shared_context: Dict[str, List[str]]
    
    finished: bool
    reward_score: float
    achieved_text: str
    retry_needed: bool
    
    strategy: str
    current_purpose: str